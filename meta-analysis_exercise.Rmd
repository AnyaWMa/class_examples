---
title: "Meta-Analysis Demo"
author: "Psych 251"
date: "11/3/2021"
output: html_document
---

# Preliminaries

Packages needed for the class example. 

```{r packages}
library(tidyverse)
library(metafor)
library(here)
theme_set(theme_bw())
```

You'd need to run this next chunk if you wanted to re-download the data from MetaLab, which would also mean installing the `metalabr` package (commented out). 

```{r data, eval=FALSE}
#devtools::install_github("langcog/metalabr")
library(metalabr)
metadata <- get_metalab_metadata()
metalab_data <- get_metalab_data(filter(metadata, short_name == "mutex"))
metalab_data %>% 
  select(long_cite, short_cite, expt_num, n, d_calc, d_var_calc, 
         mean_age_months, year) %>%
  filter(mean_age_months <= 24) %>% # subset for ease
write_csv(here("data/mutex.csv"))
```

Load in the pre-cached data. 

```{r dataloading}
d <- read_csv(here("data/mutex.csv"))
```

# Basic descriptives

Always take a look at the data first.

```{r examine}
d
```

The effect sizes are in `d_calc` (for Cohen's $d$, calculated from the data). 

```{r hist}
ggplot(d, aes(x = d_calc)) + 
  geom_histogram(binwidth = .1) + 
  xlab("Effect Size (d)")
```

Since these are developmental data, we can plot them against age. 

```{r ageplot}
ggplot(d, aes(x = mean_age_months, y = d_calc)) + 
  geom_point(aes(size = n), alpha = .5) + 
  geom_smooth(method = "lm") + 
  xlab("Mean age (months)") + 
  ylab("Effect size (d)") + 
  geom_hline(lty = 2, yintercept = 0)
```

# Meta-analysis

Random effects meta-analysis - this is the default for `metafor`. The main command for metafor is `rma` - that's like the `lm` (linear model) or `lmer` (linear mixed effects model of the `lme4` package). 

```{r ranef}
random_effects_mod <- rma(yi = d_calc, vi = d_var_calc, 
                          slab = short_cite, data = d)
summary(random_effects_mod)
```
Investigate heterogeneity if we remove the outlier.

```{r}
d_post_hoc_pruned <- filter(d, d_calc < 1 & d_calc > 0)
random_effects_posthoc_mod <- rma(yi = d_calc, vi = d_var_calc, 
                          slab = short_cite, data = d_post_hoc_pruned)
summary(random_effects_posthoc_mod)
```



For kicks, try fixed effects. 

```{r fixef}
fixed_effects_mod <- rma(yi = d_calc, vi = d_var_calc, 
                          slab = short_cite, data = d, method = "FE")
summary(fixed_effects_mod)
```

# Forest plot

`metafor` also lets you create forest plots. 

```{r forest-ranef}
forest(random_effects_mod)
```

Compare to the forest plot for the fixed effects model.

```{r forest-fixef}
forest(fixed_effects_mod)
```

# Funnel plot

A funnel plot can be used to diagnose publication bias (though it's not the most sensitive way to do so).

```{r funnel}
funnel(random_effects_mod)
```


# Meta-regression

Meta-regression asks whether study-level covariates (like say year of publication or average age of kids) are related to the effect size. 

```{r metareg-age}
meta_reg_model <- rma(yi = d_calc, vi = d_var_calc, 
                      mods = ~ mean_age_months, 
                      slab = short_cite, data = d)
summary(meta_reg_model)
```
Try asking if publication `year` is a significant meta-regressor.

```{r metareg-year}

```

# Example for mini-metas

## Find the set of results

For your mini-meta, you'll already have 3 (original, replication, rescue). You'll want to look for any other direct replications of the original, but a forward citation search can help with that. 

> Here we'll do a worked example on Risen and Gilovich (2008) and it's replications, which are conveniently summarized in Many Labs 5: Registered Multisite Replication of the Tempting-Fate Effects in Risen and Gilovich (2008). (https://journals.sagepub.com/doi/full/10.1177/2515245918785165#bibr2-2515245918785165)

> There's the original, an RP:P, and three samples from Many Labs 5. 

## Calculate effect sizes

* What's the key result you're interested in -- a main condition difference, an interaction term

> This paper has both -- "Risen and Gilovich (2008) found that subjects believed that “tempting fate” would be punished with ironic bad outcomes (a main effect), and that this effect was magnified when subjects were under cognitive load (an interaction)."

> I'll work through the main effect. 

```{r}
raw_data <- read_csv(here("data/mini_meta_example_data.csv"))

raw_data
```

Different studies had different numbers reported so you may need to standardize.

However, with a mini-meta of replications, you may have everything on the same scale already. 

```{r mod}
for_mod <- raw_data |> 
  mutate(se=(raw_high-raw_low)/(2*1.96))

mini_meta_mod <- rma(yi=raw_mean, sei=se, slab=Study, data=for_mod)

summary(mini_meta_mod)


```
```{r plot}
aggregate <- tibble(Study="aggregate", Citation=NA,N=NA, raw_mean=mini_meta_mod$b,
                    raw_low=mini_meta_mod$ci.lb, raw_high=mini_meta_mod$ci.ub)

for_plot <- raw_data |> bind_rows(aggregate) |> mutate(Study=factor(Study, levels=c("aggregate", "ml5-dis", "ml5-sim", "ml5-mturk", "rpp", "original")))


ggplot(for_plot,aes(x=Study,y=raw_mean,ymin=raw_low,ymax=raw_high))+
  geom_errorbar(colour='darkgray',size=.5,width=.25)+
  geom_point(aes(size=sqrt(N)))+
  geom_point(data=for_plot |> filter(Study=="aggregate"), shape=18, size=4)+
  coord_flip()+
  geom_hline(yintercept=0,color="black")+
  theme(legend.position = "none")+
  labs(y="Main effect size on original scale", x="")
```

# Now try their interaction effect


```{r}
raw_interaction <- read_csv(here("data/mini_meta_example_data_interaction.csv"))

```

```{r model}


```
```{r plot}

```
# Tools for effect size wrangling

metafor::escalc()

many functions in compute.es package

https://github.com/vboyce/251-254-MA/blob/main/code/helper/parse_stats.R (what I wrote for replication meta-analysis)

https://github.com/AaronChuey/online_devo_metaanalysis/blob/main/scripts/compute_es.R (from people doing prep for metalab datasets)
